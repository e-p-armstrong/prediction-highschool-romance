{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "46720d7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-29 01:02:24.962073: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "431/782 [===============>..............] - ETA: 27s - loss: 4.9475 - accuracy: 0.0559"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 17\u001b[0m\n\u001b[1;32m     15\u001b[0m loss_fn \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mlosses\u001b[38;5;241m.\u001b[39mSparseCategoricalCrossentropy(from_logits\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m     16\u001b[0m model\u001b[38;5;241m.\u001b[39mcompile(optimizer\u001b[38;5;241m=\u001b[39mAdam(), loss\u001b[38;5;241m=\u001b[39mloss_fn, metrics\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[0;32m---> 17\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m64\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.8/site-packages/keras/utils/traceback_utils.py:65\u001b[0m, in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     64\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m---> 65\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint: disable=broad-except\u001b[39;00m\n\u001b[1;32m     66\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m     67\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.8/site-packages/keras/engine/training.py:1650\u001b[0m, in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1602\u001b[0m \u001b[38;5;129m@traceback_utils\u001b[39m\u001b[38;5;241m.\u001b[39mfilter_traceback\n\u001b[1;32m   1603\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mevaluate\u001b[39m(\u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   1604\u001b[0m              x\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1614\u001b[0m              return_dict\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m   1615\u001b[0m              \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m   1616\u001b[0m   \u001b[38;5;124;03m\"\"\"Returns the loss value & metrics values for the model in test mode.\u001b[39;00m\n\u001b[1;32m   1617\u001b[0m \n\u001b[1;32m   1618\u001b[0m \u001b[38;5;124;03m  Computation is done in batches (see the `batch_size` arg.)\u001b[39;00m\n\u001b[1;32m   1619\u001b[0m \n\u001b[1;32m   1620\u001b[0m \u001b[38;5;124;03m  Args:\u001b[39;00m\n\u001b[1;32m   1621\u001b[0m \u001b[38;5;124;03m      x: Input data. It could be:\u001b[39;00m\n\u001b[1;32m   1622\u001b[0m \u001b[38;5;124;03m        - A Numpy array (or array-like), or a list of arrays\u001b[39;00m\n\u001b[1;32m   1623\u001b[0m \u001b[38;5;124;03m          (in case the model has multiple inputs).\u001b[39;00m\n\u001b[1;32m   1624\u001b[0m \u001b[38;5;124;03m        - A TensorFlow tensor, or a list of tensors\u001b[39;00m\n\u001b[1;32m   1625\u001b[0m \u001b[38;5;124;03m          (in case the model has multiple inputs).\u001b[39;00m\n\u001b[1;32m   1626\u001b[0m \u001b[38;5;124;03m        - A dict mapping input names to the corresponding array/tensors,\u001b[39;00m\n\u001b[1;32m   1627\u001b[0m \u001b[38;5;124;03m          if the model has named inputs.\u001b[39;00m\n\u001b[1;32m   1628\u001b[0m \u001b[38;5;124;03m        - A `tf.data` dataset. Should return a tuple\u001b[39;00m\n\u001b[1;32m   1629\u001b[0m \u001b[38;5;124;03m          of either `(inputs, targets)` or\u001b[39;00m\n\u001b[1;32m   1630\u001b[0m \u001b[38;5;124;03m          `(inputs, targets, sample_weights)`.\u001b[39;00m\n\u001b[1;32m   1631\u001b[0m \u001b[38;5;124;03m        - A generator or `keras.utils.Sequence` returning `(inputs, targets)`\u001b[39;00m\n\u001b[1;32m   1632\u001b[0m \u001b[38;5;124;03m          or `(inputs, targets, sample_weights)`.\u001b[39;00m\n\u001b[1;32m   1633\u001b[0m \u001b[38;5;124;03m        A more detailed description of unpacking behavior for iterator types\u001b[39;00m\n\u001b[1;32m   1634\u001b[0m \u001b[38;5;124;03m        (Dataset, generator, Sequence) is given in the `Unpacking behavior\u001b[39;00m\n\u001b[1;32m   1635\u001b[0m \u001b[38;5;124;03m        for iterator-like inputs` section of `Model.fit`.\u001b[39;00m\n\u001b[1;32m   1636\u001b[0m \u001b[38;5;124;03m      y: Target data. Like the input data `x`, it could be either Numpy\u001b[39;00m\n\u001b[1;32m   1637\u001b[0m \u001b[38;5;124;03m        array(s) or TensorFlow tensor(s). It should be consistent with `x`\u001b[39;00m\n\u001b[1;32m   1638\u001b[0m \u001b[38;5;124;03m        (you cannot have Numpy inputs and tensor targets, or inversely). If\u001b[39;00m\n\u001b[1;32m   1639\u001b[0m \u001b[38;5;124;03m        `x` is a dataset, generator or `keras.utils.Sequence` instance, `y`\u001b[39;00m\n\u001b[1;32m   1640\u001b[0m \u001b[38;5;124;03m        should not be specified (since targets will be obtained from the\u001b[39;00m\n\u001b[1;32m   1641\u001b[0m \u001b[38;5;124;03m        iterator/dataset).\u001b[39;00m\n\u001b[1;32m   1642\u001b[0m \u001b[38;5;124;03m      batch_size: Integer or `None`. Number of samples per batch of\u001b[39;00m\n\u001b[1;32m   1643\u001b[0m \u001b[38;5;124;03m        computation. If unspecified, `batch_size` will default to 32. Do not\u001b[39;00m\n\u001b[1;32m   1644\u001b[0m \u001b[38;5;124;03m        specify the `batch_size` if your data is in the form of a dataset,\u001b[39;00m\n\u001b[1;32m   1645\u001b[0m \u001b[38;5;124;03m        generators, or `keras.utils.Sequence` instances (since they generate\u001b[39;00m\n\u001b[1;32m   1646\u001b[0m \u001b[38;5;124;03m        batches).\u001b[39;00m\n\u001b[1;32m   1647\u001b[0m \u001b[38;5;124;03m      verbose: `\"auto\"`, 0, 1, or 2. Verbosity mode.\u001b[39;00m\n\u001b[1;32m   1648\u001b[0m \u001b[38;5;124;03m          0 = silent, 1 = progress bar, 2 = single line.\u001b[39;00m\n\u001b[1;32m   1649\u001b[0m \u001b[38;5;124;03m          `\"auto\"` defaults to 1 for most cases, and to 2 when used with\u001b[39;00m\n\u001b[0;32m-> 1650\u001b[0m \u001b[38;5;124;03m          `ParameterServerStrategy`. Note that the progress bar is not\u001b[39;00m\n\u001b[1;32m   1651\u001b[0m \u001b[38;5;124;03m          particularly useful when logged to a file, so `verbose=2` is\u001b[39;00m\n\u001b[1;32m   1652\u001b[0m \u001b[38;5;124;03m          recommended when not running interactively (e.g. in a production\u001b[39;00m\n\u001b[1;32m   1653\u001b[0m \u001b[38;5;124;03m          environment).\u001b[39;00m\n\u001b[1;32m   1654\u001b[0m \u001b[38;5;124;03m      sample_weight: Optional Numpy array of weights for the test samples,\u001b[39;00m\n\u001b[1;32m   1655\u001b[0m \u001b[38;5;124;03m        used for weighting the loss function. You can either pass a flat (1D)\u001b[39;00m\n\u001b[1;32m   1656\u001b[0m \u001b[38;5;124;03m        Numpy array with the same length as the input samples\u001b[39;00m\n\u001b[1;32m   1657\u001b[0m \u001b[38;5;124;03m          (1:1 mapping between weights and samples), or in the case of\u001b[39;00m\n\u001b[1;32m   1658\u001b[0m \u001b[38;5;124;03m            temporal data, you can pass a 2D array with shape `(samples,\u001b[39;00m\n\u001b[1;32m   1659\u001b[0m \u001b[38;5;124;03m            sequence_length)`, to apply a different weight to every timestep\u001b[39;00m\n\u001b[1;32m   1660\u001b[0m \u001b[38;5;124;03m            of every sample. This argument is not supported when `x` is a\u001b[39;00m\n\u001b[1;32m   1661\u001b[0m \u001b[38;5;124;03m            dataset, instead pass sample weights as the third element of `x`.\u001b[39;00m\n\u001b[1;32m   1662\u001b[0m \u001b[38;5;124;03m      steps: Integer or `None`. Total number of steps (batches of samples)\u001b[39;00m\n\u001b[1;32m   1663\u001b[0m \u001b[38;5;124;03m        before declaring the evaluation round finished. Ignored with the\u001b[39;00m\n\u001b[1;32m   1664\u001b[0m \u001b[38;5;124;03m        default value of `None`. If x is a `tf.data` dataset and `steps` is\u001b[39;00m\n\u001b[1;32m   1665\u001b[0m \u001b[38;5;124;03m        None, 'evaluate' will run until the dataset is exhausted. This\u001b[39;00m\n\u001b[1;32m   1666\u001b[0m \u001b[38;5;124;03m        argument is not supported with array inputs.\u001b[39;00m\n\u001b[1;32m   1667\u001b[0m \u001b[38;5;124;03m      callbacks: List of `keras.callbacks.Callback` instances. List of\u001b[39;00m\n\u001b[1;32m   1668\u001b[0m \u001b[38;5;124;03m        callbacks to apply during evaluation. See\u001b[39;00m\n\u001b[1;32m   1669\u001b[0m \u001b[38;5;124;03m        [callbacks](/api_docs/python/tf/keras/callbacks).\u001b[39;00m\n\u001b[1;32m   1670\u001b[0m \u001b[38;5;124;03m      max_queue_size: Integer. Used for generator or `keras.utils.Sequence`\u001b[39;00m\n\u001b[1;32m   1671\u001b[0m \u001b[38;5;124;03m        input only. Maximum size for the generator queue. If unspecified,\u001b[39;00m\n\u001b[1;32m   1672\u001b[0m \u001b[38;5;124;03m        `max_queue_size` will default to 10.\u001b[39;00m\n\u001b[1;32m   1673\u001b[0m \u001b[38;5;124;03m      workers: Integer. Used for generator or `keras.utils.Sequence` input\u001b[39;00m\n\u001b[1;32m   1674\u001b[0m \u001b[38;5;124;03m        only. Maximum number of processes to spin up when using process-based\u001b[39;00m\n\u001b[1;32m   1675\u001b[0m \u001b[38;5;124;03m        threading. If unspecified, `workers` will default to 1.\u001b[39;00m\n\u001b[1;32m   1676\u001b[0m \u001b[38;5;124;03m      use_multiprocessing: Boolean. Used for generator or\u001b[39;00m\n\u001b[1;32m   1677\u001b[0m \u001b[38;5;124;03m        `keras.utils.Sequence` input only. If `True`, use process-based\u001b[39;00m\n\u001b[1;32m   1678\u001b[0m \u001b[38;5;124;03m        threading. If unspecified, `use_multiprocessing` will default to\u001b[39;00m\n\u001b[1;32m   1679\u001b[0m \u001b[38;5;124;03m        `False`. Note that because this implementation relies on\u001b[39;00m\n\u001b[1;32m   1680\u001b[0m \u001b[38;5;124;03m        multiprocessing, you should not pass non-picklable arguments to the\u001b[39;00m\n\u001b[1;32m   1681\u001b[0m \u001b[38;5;124;03m        generator as they can't be passed easily to children processes.\u001b[39;00m\n\u001b[1;32m   1682\u001b[0m \u001b[38;5;124;03m      return_dict: If `True`, loss and metric results are returned as a dict,\u001b[39;00m\n\u001b[1;32m   1683\u001b[0m \u001b[38;5;124;03m        with each key being the name of the metric. If `False`, they are\u001b[39;00m\n\u001b[1;32m   1684\u001b[0m \u001b[38;5;124;03m        returned as a list.\u001b[39;00m\n\u001b[1;32m   1685\u001b[0m \u001b[38;5;124;03m      **kwargs: Unused at this time.\u001b[39;00m\n\u001b[1;32m   1686\u001b[0m \n\u001b[1;32m   1687\u001b[0m \u001b[38;5;124;03m  See the discussion of `Unpacking behavior for iterator-like inputs` for\u001b[39;00m\n\u001b[1;32m   1688\u001b[0m \u001b[38;5;124;03m  `Model.fit`.\u001b[39;00m\n\u001b[1;32m   1689\u001b[0m \n\u001b[1;32m   1690\u001b[0m \u001b[38;5;124;03m  Returns:\u001b[39;00m\n\u001b[1;32m   1691\u001b[0m \u001b[38;5;124;03m      Scalar test loss (if the model has a single output and no metrics)\u001b[39;00m\n\u001b[1;32m   1692\u001b[0m \u001b[38;5;124;03m      or list of scalars (if the model has multiple outputs\u001b[39;00m\n\u001b[1;32m   1693\u001b[0m \u001b[38;5;124;03m      and/or metrics). The attribute `model.metrics_names` will give you\u001b[39;00m\n\u001b[1;32m   1694\u001b[0m \u001b[38;5;124;03m      the display labels for the scalar outputs.\u001b[39;00m\n\u001b[1;32m   1695\u001b[0m \n\u001b[1;32m   1696\u001b[0m \u001b[38;5;124;03m  Raises:\u001b[39;00m\n\u001b[1;32m   1697\u001b[0m \u001b[38;5;124;03m      RuntimeError: If `model.evaluate` is wrapped in a `tf.function`.\u001b[39;00m\n\u001b[1;32m   1698\u001b[0m \u001b[38;5;124;03m  \"\"\"\u001b[39;00m\n\u001b[1;32m   1699\u001b[0m   base_layer\u001b[38;5;241m.\u001b[39mkeras_api_gauge\u001b[38;5;241m.\u001b[39mget_cell(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mevaluate\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39mset(\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m   1700\u001b[0m   version_utils\u001b[38;5;241m.\u001b[39mdisallow_legacy_graph(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mModel\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mevaluate\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.8/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.8/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:880\u001b[0m, in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.8/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:912\u001b[0m, in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.8/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compiler.py:134\u001b[0m, in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.8/site-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py:1745\u001b[0m, in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.8/site-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py:378\u001b[0m, in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.8/site-packages/tensorflow/python/eager/execute.py:52\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     50\u001b[0m device_name \u001b[38;5;241m=\u001b[39m ctx\u001b[38;5;241m.\u001b[39mdevice_name\n\u001b[1;32m     51\u001b[0m \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[0;32m---> 52\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m     54\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m pywrap_tfe\u001b[38;5;241m.\u001b[39mTFE_Py_Execute(ctx\u001b[38;5;241m.\u001b[39m_handle, device_name, op_name,\n\u001b[1;32m     55\u001b[0m                                       inputs, attrs, num_outputs)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.optimizers.legacy import Adam\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "cifar = tf.keras.datasets.cifar100\n",
    "(x_train, y_train), (x_test, y_test) = cifar.load_data()\n",
    "model = tf.keras.applications.ResNet50(\n",
    "    include_top=True,\n",
    "    weights=None,\n",
    "    input_shape=(32, 32, 3),\n",
    "    classes=100,)\n",
    "\n",
    "loss_fn = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "model.compile(optimizer=Adam(), loss=loss_fn, metrics=[\"accuracy\"])\n",
    "model.fit(x_train, y_train, epochs=5, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5a7dd79",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
